# Competencia Kaggle: Predicci贸n de Personalidad Introvertido vs. Extrovertido

Este repositorio contiene la soluci贸n para la competencia de Kaggle **"Predict the Introverts from the Extroverts"**. El objetivo del proyecto fue desarrollar un modelo de machine learning capaz de clasificar la personalidad de un individuo como introvertida o extrovertida bas谩ndose en las respuestas de un cuestionario.

A trav茅s de un proceso sistem谩tico de an谩lisis, preprocesamiento avanzado, optimizaci贸n de modelos y ensamblado, se logr贸 un **Top Score de 0.9757** en la tabla de clasificaci贸n de Kaggle.

## Dataset
El conjunto de datos fue proporcionado por la competencia en Kaggle y se divide en un set de entrenamiento y uno de prueba.
* **Fuente:** [Predict the Introverts from the Extroverts Kaggle Competition](https://www.kaggle.com/competitions/playground-series-s5e7)
* **Caracter铆sticas Principales:** Incluyen respuestas num茅ricas y categ贸ricas a preguntas como `Time_spent_Alone`, `Stage_fear`, `Going_outside`, y `Friends_circle_size`.
* **Variable Objetivo:** `Personality` (Clasificaci贸n binaria: 'Introvert' o 'Extrovert').

## Flujo de Trabajo y Metodolog铆a
El proyecto se estructur贸 en dos fases principales, documentadas en dos notebooks separados, para demostrar un enfoque desde lo fundamental hasta lo avanzado.

#### 1. An谩lisis Exploratorio de Datos (EDA)
Se realiz贸 un an谩lisis exhaustivo para entender la naturaleza de los datos. Los hallazgos clave incluyeron:
* Fuertes correlaciones entre varias caracter铆sticas y la variable objetivo.
* Un **desbalance de clases** significativo, con una mayor proporci贸n de extrovertidos.

#### 2. Preprocesamiento de Datos
Se exploraron dos estrategias de imputaci贸n para manejar los valores nulos:
* **Notebook 1 (Base):** Se utiliz贸 la **imputaci贸n por la mediana**, un m茅todo robusto y computacionalmente eficiente.
* **Notebook 2 (Avanzado):** Se implement贸 el **`IterativeImputer`** de Scikit-learn, un m茅todo multivariado que estima cada valor faltante bas谩ndose en las dem谩s caracter铆sticas para lograr una imputaci贸n m谩s precisa.

#### 3. Modelado y Selecci贸n
Se evalu贸 el rendimiento de varios algoritmos de clasificaci贸n potentes:
* `RandomForestClassifier`
* `XGBoost`
* `LightGBM`

El **`RandomForestClassifier`** demostr贸 consistentemente ser el modelo individual m谩s fuerte en este problema.

#### 4. Optimizaci贸n de Hiperpar谩metros
Para maximizar el rendimiento, se utilizaron dos t茅cnicas de optimizaci贸n:
* **`GridSearchCV`:** Para una b煤squeda exhaustiva en un espacio de par谩metros definido.
* **`Optuna`:** Para una b煤squeda m谩s inteligente y eficiente utilizando optimizaci贸n bayesiana.

#### 5. Ensamble de Modelos
Se experiment贸 con t茅cnicas de ensamblado para buscar una mejora final:
* **`VotingClassifier`:** Combinando las predicciones de los mejores modelos.
* **`StackingClassifier`:** Implementando un meta-modelo para aprender a combinar las predicciones de forma 贸ptima.

Curiosamente, se descubri贸 que el **modelo `RandomForestClassifier` individual, una vez optimizado, superaba a los ensambles**, demostrando su robustez y adecuaci贸n para este dataset.

## Resultados
El proceso de experimentaci贸n y optimizaci贸n culmin贸 en un modelo de alto rendimiento.

* **Modelo Campe贸n :** `RandomForestClassifier`
* **M茅todo de Preprocesamiento:** Imputaci贸n de nulos con **`IterativeImputer`**.
* **Mejores Hiperpar谩metros:**
    * `max_depth`: 20
    * `min_samples_leaf`: 2
    * `n_estimators`: 200
* **Score Final en Kaggle:** **0.975708**

## Conclusi贸n
Este proyecto demuestra un flujo de trabajo completo de machine learning, desde el an谩lisis inicial hasta la optimizaci贸n avanzada. La conclusi贸n clave es doble:
1.  Las t茅cnicas de preprocesamiento avanzado como **`IterativeImputer`** pueden ofrecer mejoras significativas sobre m茅todos m谩s simples.
2.  Un **modelo individual robusto y bien optimizado** (`RandomForestClassifier` en este caso) a veces puede ser superior a ensambles m谩s complejos, destacando la importancia de la selecci贸n y ajuste del modelo.

El resultado final valida la efectividad de un enfoque met贸dico y experimental para resolver problemas de clasificaci贸n.
